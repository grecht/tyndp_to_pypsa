{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f04a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from geopy.geocoders import Nominatim\n",
    "from geopy import *\n",
    "import geopy.distance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import re\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1280a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = r'2020/transmission.xlsx'\n",
    "sheet = 'Trans.Investments'\n",
    "\n",
    "df = pd.read_excel(excel, sheet_name=sheet, header=[1])\n",
    "\n",
    "# TODO: also contains new substations!\n",
    "\n",
    "wanted_columns = ['Investment number',\n",
    "                  'This investment belongs to project numberâ€¦',\n",
    "                  'Commissioning Year',\n",
    "                  'Status ID\\n1 : Under Consideration,\\n2 : In Planning but not permitting,\\n3 : In permitting,\\n4 : Under Construction',\n",
    "                  'Type of Element',\n",
    "                  'Substation From',\n",
    "                  'Substation To',\n",
    "                  'Technology',\n",
    "                  'Total route length (km)']\n",
    "status_column = wanted_columns[3]\n",
    "df[wanted_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88615986",
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted    = df[wanted_columns]\n",
    "# only choose those in permitting or under construction\n",
    "wanted    = wanted.loc[wanted[status_column].astype(int) >= 3]\n",
    "\n",
    "ac_lines  = wanted.query(\"`Type of Element` == 'ACTransmissionLine'\")\n",
    "dc_lines  = wanted.query(\"`Type of Element` == 'DCTransmissionLine'\")\n",
    "on_subst  = wanted.query(\"`Type of Element` == 'OnshoreSubstation'\")\n",
    "off_subst = wanted.query(\"`Type of Element` == 'OffshoreSubstation'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d05c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the time being, remove lines connected to new substations\n",
    "new_subst = set(on_subst['Substation From']).union(on_subst['Substation To'])\n",
    "ac_lines  = ac_lines.query(\"`Substation From` not in @new_subst\")\n",
    "ac_lines  = ac_lines.query(\"`Substation To` not in @new_subst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227980dd",
   "metadata": {},
   "source": [
    "# Use bus names from buses.csv (v0.1.0)\n",
    "See https://github.com/PyPSA/pypsa-eur/blob/v0.1.0rc/data/entsoegridkit/buses.csv. Data is from 2017 (newer gridkit extracts do not contain 'tags' with substation names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f64fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "buses_file = 'buses_v0.1.0.csv'\n",
    "\n",
    "# see base_network.py in PyPSA-Eur repository\n",
    "buses = (pd.read_csv(buses_file, quotechar=\"'\",\n",
    "                     true_values='t', false_values='f',\n",
    "                     dtype=dict(bus_id=\"str\"))\n",
    "        .set_index(\"bus_id\")\n",
    "        .drop(['station_id'], axis=1)\n",
    "        .rename(columns=dict(voltage='v_nom')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd83de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tags = buses.tags.isnull().sum()\n",
    "print(f'{no_tags} buses have no tags.')\n",
    "\n",
    "yes_tags = buses.tags.notnull().sum()\n",
    "print(f'{yes_tags} buses have tags.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "buses = buses.query('tags.notnull()', engine='python')\n",
    "buses = buses.query(\"symbol == 'Substation'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b348fe43",
   "metadata": {},
   "source": [
    "# Extract 'name_eng' and 'country' from tags in  buses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_regex = r'(\"\\w+\"=>\"[^\"]*\"),' # Form: 'key => value, key => value, ...'\n",
    "\n",
    "tag_regex   = r'\"(?P<key>\\w+)\"=>\"(?P<value>[^\"]*)\"' # Form: 'key => value'\n",
    "tag_pattern = re.compile(tag_regex)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for index, row in buses.iterrows():\n",
    "    name    = ''\n",
    "    country = ''\n",
    "    x = row['x']\n",
    "    y = row['y']\n",
    "    \n",
    "    tags_string = row['tags']\n",
    "    \n",
    "    tags = re.split(split_regex, tags_string)\n",
    "    \n",
    "    # Remove whitespaces at front and end, remove None values\n",
    "    tags = [s.strip() for s in tags]\n",
    "    tags = list(filter(None, tags))\n",
    "    \n",
    "    for tag in tags:\n",
    "        m = tag_pattern.match(tag)\n",
    "            \n",
    "        if m is None:\n",
    "            print(tag)\n",
    "            \n",
    "        # see group names in tag_regex\n",
    "        key   = m.group('key')\n",
    "        value = m.group('value')\n",
    "        \n",
    "        if key == 'name_eng':\n",
    "            name = value.strip()\n",
    "        elif key == 'country':\n",
    "            country = value.strip()\n",
    "    \n",
    "    if name == 'unknown' or not name:\n",
    "        continue\n",
    "        \n",
    "    rows.append((name, country, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29974e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_buses = pd.DataFrame.from_records(rows, columns=['name', 'country', 'x', 'y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae7ef5d",
   "metadata": {},
   "source": [
    "## Remove duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_buses = curated_buses.loc[~curated_buses.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2290b",
   "metadata": {},
   "source": [
    "## There are substations which share the same name but have different coordinates\n",
    "- large deviation between coordinates => substations are most likely in different countries \n",
    "    - BUT: it does occur that different places in the same country get the same name\n",
    "- small deviation between coordinates => reference to same substation (error in gridextract?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d2b78-ae5b-484e-8217-c4e62a9a902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pypsa_countries = ['AL', 'AT', 'BA', 'BE', 'BG', 'CH', 'CZ', 'DE', 'DK', 'EE', 'ES', 'FI', 'FR', 'GB', 'GR', 'HR', 'HU', 'IE', 'IT', 'LT', 'LU', 'LV', 'ME', 'MK', 'NL', 'NO', 'PL', 'PT', 'RO', 'RS', 'SE', 'SI', 'SK']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b887fba6",
   "metadata": {},
   "source": [
    "### List of all duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54bed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated = curated_buses.loc[curated_buses.name.duplicated()]\n",
    "duplicated = duplicated.query(\"country in @pypsa_countries\")\n",
    "\n",
    "for name in duplicated.name.unique():\n",
    "    print(name)\n",
    "    for index, row in curated_buses.query('name == @name').iterrows():\n",
    "        print(f\"({row['x']}, {row['y']}), {row['country']}\")\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd52f56",
   "metadata": {},
   "source": [
    "### Same name and country, large deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794d0466",
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_buses.query(\"name == 'Yuzhnaya'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff8fde",
   "metadata": {},
   "source": [
    "### Same name, different country, large deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfcda96",
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_buses.query(\"name == 'Saida'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77525d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_buses.query(\"name == 'Titan'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255686b8",
   "metadata": {},
   "source": [
    "## (TODO) Add new substations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4207b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_subst\n",
    "\n",
    "# extract country if it matches regex\n",
    "# otherwise, np.NAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883dc969",
   "metadata": {},
   "source": [
    "## Remove '(\\<Country Code\\>) ' from tyndp substation name strings, add new column instead\n",
    "Otherwise, this could negatively impact the Levenshtein distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "subst_regex   = r'(?P<place>.+)\\s?[\\[(](?P<country>\\w{2})[)\\]]' # Form: 'Glorenza (IT)'\n",
    "subst_pattern = re.compile(subst_regex)\n",
    "\n",
    "# use this if other pattern does not match to remove comments in parentheses\n",
    "# e.g. 'Molai (through Sklavouna Terminal)'\n",
    "alt_regex   = r'(?P<place>.+)\\s?[\\[(].*[)\\]]'\n",
    "alt_pattern = re.compile(alt_regex)\n",
    "\n",
    "fr_names     = []\n",
    "fr_countries = []\n",
    "to_names     = []\n",
    "to_countries = []\n",
    "\n",
    "for index, row in ac_lines.iterrows():    \n",
    "    fr = row['Substation From']\n",
    "    to = row['Substation To']\n",
    "    \n",
    "    # default values if regex does not match\n",
    "    fr_name = fr\n",
    "    to_name = to    \n",
    "    fr_country = np.NAN\n",
    "    to_country = np.NAN\n",
    "    \n",
    "    fr_match = subst_pattern.match(fr)\n",
    "    to_match = subst_pattern.match(to)\n",
    "    \n",
    "    if fr_match:\n",
    "        fr_name    = fr_match.group('place').strip()\n",
    "        fr_country = fr_match.group('country').strip()\n",
    "    else:\n",
    "        fr_alt_match = alt_pattern.match(fr)\n",
    "        if fr_alt_match:\n",
    "            fr_name = fr_alt_match.group('place')\n",
    "        \n",
    "    if to_match:\n",
    "        to_name    = to_match.group('place').strip()\n",
    "        to_country = to_match.group('country').strip()\n",
    "    else:        \n",
    "        to_alt_match = alt_pattern.match(to)\n",
    "        if to_alt_match:\n",
    "            to_name = to_alt_match.group('place')\n",
    "        \n",
    "    fr_names.append(fr_name)\n",
    "    fr_countries.append(fr_country)\n",
    "    to_names.append(to_name)\n",
    "    to_countries.append(to_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361367fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_lines['Substation From'] = fr_names\n",
    "ac_lines['Substation To'] = to_names\n",
    "ac_lines['Country1'] = fr_countries\n",
    "ac_lines['Country2'] = to_countries\n",
    "ac_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c767ca",
   "metadata": {},
   "source": [
    "## create mapping from all unique tyndp substation names to substation names from 'buses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56275746",
   "metadata": {},
   "outputs": [],
   "source": [
    "tyndp_subs   = set(ac_lines['Substation From']).union(set(ac_lines['Substation To']))\n",
    "tyndp_to_bus = {}\n",
    "\n",
    "for tyndp in tyndp_subs:\n",
    "    buses_subs = curated_buses.name.values\n",
    "    \n",
    "    closest = min([(bus, Levenshtein.distance(bus.lower(), tyndp.lower())) for bus in buses_subs], key=lambda t: t[1])[0]\n",
    "    \n",
    "    tyndp_to_bus[tyndp] = closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e700c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tyndp_to_bus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40e12a5",
   "metadata": {},
   "source": [
    "### Helper functions: Out of all possible pairs of locations from two lists, get the pair whose distance is closest to the specified (line) length\n",
    "Deals with problem of multiple places in same country sharing a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3897722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coords(rows):\n",
    "    coordinates = []\n",
    "    for index, row in rows.iterrows():\n",
    "        coordinates.append((row['x'], row['y']))\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_pair_with_length(s1_rows, s2_rows, length):\n",
    "    s1_coords = extract_coords(s1_rows)\n",
    "    s2_coords = extract_coords(s2_rows)\n",
    "    \n",
    "    combinations  = list(itertools.product(s1_coords, s2_coords))\n",
    "    with_distance = [(a, b, geopy.distance.distance(a,b).km) for (a,b) in combinations]\n",
    "    \n",
    "    best_match = min(with_distance, key=lambda t: abs(length - t[2]))\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cafe9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "buses_s1 = curated_buses.loc[curated_buses['name'] == 'Yuzhnaya']\n",
    "buses_s2 = curated_buses.loc[curated_buses['name'] == 'Liteynaya']\n",
    "\n",
    "best = match_pair_with_length(buses_s1, buses_s2, 430)\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d7e8e7",
   "metadata": {},
   "source": [
    "# Match start- and endpoints of lines to substations from buses.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_to_tuples = {}\n",
    "error_tuples = {}\n",
    "\n",
    "for index, row in ac_lines.iterrows():    \n",
    "    # Get closest name match based on Levenshtein distance for start- and endpoints of line\n",
    "    fr = row['Substation From']\n",
    "    to = row['Substation To']\n",
    "    \n",
    "    fr_country = row['Country1']\n",
    "    to_country = row['Country2']\n",
    "            \n",
    "    s1 = tyndp_to_bus[fr]\n",
    "    s2 = tyndp_to_bus[to]\n",
    "    \n",
    "    # Extract respective rows in buses to determine coordinates\n",
    "    buses_s1 = curated_buses.loc[curated_buses.name == s1]\n",
    "    buses_s2 = curated_buses.loc[curated_buses.name == s2]\n",
    "    \n",
    "    # If we were able to extract country from name, restrict chosen rows to this country.\n",
    "    if not pd.isna(fr_country):\n",
    "        buses_s1 = buses_s1.loc[buses_s1['country'] == fr_country]\n",
    "    if not pd.isna(to_country):\n",
    "        buses_s2 = buses_s2.loc[buses_s2['country'] == to_country]\n",
    "    \n",
    "    # TODO: use at least one!  \n",
    "    if buses_s1.empty or buses_s2.empty:\n",
    "        # print(f'{fr}, {fr_country} <-> {to}, {to_country}')\n",
    "        tpl = (s1, np.NAN, np.NAN, s2, np.NAN, np.NAN, np.NAN)\n",
    "        error_tuples[index] = tpl\n",
    "        continue\n",
    "    \n",
    "    # Choose pair which matches length best\n",
    "    length = row['Total route length (km)']\n",
    "    (x1, y1), (x2, y2), coord_dist = match_pair_with_length(buses_s1, buses_s2, length)\n",
    "        \n",
    "    tpl = (s1, x1, y1, s2, x2, y2, coord_dist)\n",
    "    \n",
    "    # TODO: how to choose an appropriate tolerance?\n",
    "    if not math.isclose(coord_dist, length, rel_tol=0.45):\n",
    "        error_tuples[index] = tpl\n",
    "    else:\n",
    "        fr_to_tuples[index] = tpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b820657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = pd.DataFrame(index=fr_to_tuples.keys(), data=fr_to_tuples.values(), columns=['s1', 'x1', 'y1', 's2', 'x2', 'y2', 'coord_dist'])\n",
    "\n",
    "result = ac_lines.copy()\n",
    "result = result.join(coordinates)\n",
    "\n",
    "percentage = coordinates.index.size / ac_lines.index.size\n",
    "print(f'{percentage * 100}% of lines are probably correct.')\n",
    "\n",
    "print('Lines where we probably found the correct coordinates:')\n",
    "result.loc[~result.s1.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad8f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_lines = result.loc[result.s1.isna()]\n",
    "error_subst = set(error_lines['Substation From']).union(error_lines['Substation To'])\n",
    "\n",
    "print('')\n",
    "{(k,tyndp_to_bus[k]) for k in error_subst}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6ff0b4",
   "metadata": {},
   "source": [
    "# Determine coordinates using geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09934ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "locator = Nominatim(user_agent='esm_group')\n",
    "geocode = RateLimiter(locator.geocode, min_delay_seconds=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350301a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = []\n",
    "y1 = []\n",
    "x2 = []\n",
    "y2 = []\n",
    "\n",
    "error_rows = []\n",
    "\n",
    "for index, row in ac_lines.iterrows():\n",
    "    fr   = row['Substation From']\n",
    "    to   = row['Substation To']\n",
    "    dist = row['Total route length (km)']\n",
    "\n",
    "    fr_loc = geocode(fr)\n",
    "    to_loc = geocode(to)\n",
    "\n",
    "    if fr_loc is None or to_loc is None:\n",
    "        error_rows.append([row.values])\n",
    "        continue\n",
    "        \n",
    "    fr_coords  = fr_loc.latitude, fr_loc.longitude\n",
    "    to_coords  = to_loc.latitude, to_loc.longitude\n",
    "    coord_dist = distance.distance(fr_coords, to_coords).km\n",
    "\n",
    "    if math.isclose(coord_dist, dist, rel_tol=0.25):\n",
    "        x1.append(fr_coords[0])\n",
    "        y1.append(fr_coords[1])\n",
    "        \n",
    "        x2.append(to_coords[0])\n",
    "        y2.append(to_coords[1])\n",
    "    else:\n",
    "        error_rows.append([row.values])\n",
    "        # x1.append(np.NAN)\n",
    "        # y1.append(np.NAN)\n",
    "        \n",
    "        # x2.append(np.NAN)\n",
    "        # y2.append(np.NAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9cf243",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x1), len(error_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b95b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
